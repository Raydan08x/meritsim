"""
MeritSim - OpenAI Service
Integration with OpenAI GPT for pedagogical explanations
"""
import os
import json
from typing import Optional, Dict, Any
from openai import OpenAI

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-openai-api-key")

# Initialize OpenAI client
client = None
if OPENAI_API_KEY and OPENAI_API_KEY != "your-openai-api-key":
    # Let OpenAI pick up the key from environment or handle it internally
    # Removing explicit api_key= to avoid TypeError in some httpx/openai version combinations
    client = OpenAI()


def get_openai_client():
    """Get the OpenAI client instance"""
    return client


async def generate_explanation_openai(
    question_text: str,
    correct_answer: str,
    user_answer: str,
    topic: Optional[str] = None,
    is_correct: bool = False
) -> str:
    """Generate a pedagogical explanation using OpenAI GPT."""
    if not client:
        return "Explicaci贸n no disponible. Configure la API de OpenAI."
    
    system_prompt = """Eres un tutor educativo amigable y motivador para estudiantes que preparan ex谩menes de estado en Colombia.
Tu rol es explicar conceptos de forma clara, usar un tono positivo y motivador, e incluir emojis de forma moderada.
Responde siempre en espa帽ol colombiano."""

    user_prompt = f"""{"隆El estudiante respondi贸 correctamente! " if is_correct else "El estudiante se equivoc贸, pero es una oportunidad de aprendizaje."}

Pregunta: {question_text}
Respuesta correcta: Opci贸n {correct_answer}
Respuesta del estudiante: Opci贸n {user_answer}
{"Tema: " + topic if topic else ""}

Genera una explicaci贸n educativa breve (m谩ximo 3 p谩rrafos) que:
1. {"Felicite al estudiante y refuerce por qu茅 es correcta" if is_correct else "Explique amablemente por qu茅 la respuesta correcta es la mejor opci贸n"}
2. Proporcione contexto relevante sobre el tema
3. {"Sugiera c贸mo aplicar este conocimiento" if is_correct else "Ofrezca consejos para recordar este concepto"}"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=500,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error generating OpenAI explanation: {e}")
        return "No se pudo generar la explicaci贸n en este momento."


async def generate_study_recommendation_openai(
    weak_topics: list,
    recent_errors: list
) -> str:
    """Generate personalized study recommendations using OpenAI GPT."""
    if not client:
        return "Configure la API de OpenAI para recomendaciones personalizadas."
    
    system_prompt = """Eres un asesor de estudio experto para ex谩menes de estado en Colombia.
Ofreces consejos pr谩cticos, motivadores y personalizados. Usa vi帽etas y emojis."""

    user_prompt = f"""El estudiante tiene dificultades en estos temas: {', '.join(weak_topics) if weak_topics else 'No identificados'}

Errores recientes:
{chr(10).join([f"- {e}" for e in recent_errors[:5]]) if recent_errors else "Sin errores recientes"}

Genera una recomendaci贸n de estudio personalizada que:
1. Priorice los temas m谩s d茅biles
2. Sugiera t茅cnicas de estudio espec铆ficas
3. Proponga un mini-plan de acci贸n para la pr贸xima sesi贸n
4. Sea motivador y alcanzable

Responde de forma concisa (m谩ximo 4 puntos)."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=400,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error generating OpenAI recommendation: {e}")
        return "No se pudieron generar recomendaciones en este momento."


async def chat_with_tutor(
    user_message: str,
    context: Optional[str] = None
) -> str:
    """Have a conversation with the AI tutor about study topics."""
    if not client:
        return "Configure la API de OpenAI para usar el tutor."
    
    system_prompt = """Eres MeritBot, un tutor virtual amigable especializado en preparaci贸n para ex谩menes de estado colombianos (DIAN, CAR, Acueducto).

Tus caracter铆sticas:
- Explicas conceptos de derecho administrativo, tributario y ambiental de forma simple
- Usas ejemplos pr谩cticos de Colombia
- Eres motivador y paciente
- Respondes de forma concisa pero completa
- Usas emojis moderadamente para hacer la conversaci贸n amigable

Siempre responde en espa帽ol colombiano."""

    messages = [{"role": "system", "content": system_prompt}]
    
    if context:
        messages.append({"role": "user", "content": f"Contexto actual: {context}"})
        messages.append({"role": "assistant", "content": "Entendido, tengo ese contexto en cuenta."})
    
    messages.append({"role": "user", "content": user_message})

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=600,
            temperature=0.8
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error in chat with tutor: {e}")
        return "Lo siento, hubo un error. 驴Puedes intentar de nuevo?"


async def generate_ai_question(
    entity_name: str = "General",
    topic: Optional[str] = None,
    profile_name: Optional[str] = None
) -> Dict[str, Any]:
    """Generate a random exam question using OpenAI."""
    if not client:
        return {"error": "OpenAI API not configured"}
    
    system_prompt = """Eres un experto generador de preguntas para ex谩menes de estado en Colombia (DIAN, CAR, Acueducto, CNSC).
Tu tarea es crear una pregunta de opci贸n m煤ltiple realista, desafiante y educativa.
La salida DEBE ser un JSON v谩lido con esta estructura:
{
    "text": "Texto de la pregunta",
    "option_a": "Opci贸n A",
    "option_b": "Opci贸n B",
    "option_c": "Opci贸n C",
    "option_d": "Opci贸n D",
    "correct_answer": "A, B, C o D",
    "explanation": "Explicaci贸n detallada de por qu茅 es la correcta",
    "topic": "Tema espec铆fico",
    "difficulty": 1-3
}"""

    user_prompt = f"""Genera una pregunta tipo examen para la entidad: {entity_name}.
{f"Perfil/Cargo: {profile_name}" if profile_name else ""}
{f"Tema espec铆fico: {topic}" if topic else "Tema: Cualquier tema relevante para un examen de esta entidad (Derecho, Administraci贸n, T茅cnica, etc)."}

Aseg煤rate de que la pregunta sea t茅cnica y espec铆fica del contexto colombiano.
NO inventes leyes inexistentes. Usa normativa real."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            max_tokens=600,
            temperature=0.8
        )
        content = response.choices[0].message.content
        return json.loads(content)
    except Exception as e:
        print(f"Error generating AI question: {e}")
        return {
            "error": "Failed to generate question",
            "text": "Error al generar pregunta con IA. Intenta de nuevo.",
            "option_a": "Error",
            "option_b": "Error",
            "option_c": "Error",
            "option_d": "Error", 
            "correct_answer": "A",
            "explanation": "Hubo un problema de conexi贸n con la IA."
        }
